{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Webcam Based Laser Beam Analysis Tool\n",
    "\n",
    "Webcams are flexible, inexpensive and often high resolution video cameras that can provide real-time image streaming to computers. By using image analysis tools on the image steam, a webcam can be converted into a tool for laser beam imaging and characterization. Since most beam analysis tools can be thousands of dollars, a webcam based alternative is an interesting prospect. \n",
    "\n",
    "We will implement three different beam analysis tools using a Logitech 720p webcam: real-time laser beam brightness, diameter, and centroid retrieval.\n",
    "\n",
    "First, we import the necessary libraries for our webcam beam analyzer. We will use cv2 to capture video from our webcam, skimage to analyze the image stream, numpy for some helpful methods, and matplotlib and seaborn to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from skimage.morphology import opening, closing\n",
    "from skimage.measure import moments\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "%matplotlib auto\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(style = \"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate the VideoCapture object from cv2, which will allow us to capture the camera's live stream. VideoCapture takes a device index as an argument, where 0 is the computer's default device index (e.g. a Mac's built in webcam) and 1 is the next device index, etc. To access the Logitech webcam plugged into a USB port, we use device index 1. We also disable the webcam's auto exposure and autofocus properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.0)\n",
    "cap.set(cv2.CAP_PROP_AUTOFOCUS, 0.0)\n",
    "#cap.set(cv2.CAP_PROP_GAIN, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that everything is working, we want to look at our webcam feed. We use .read( ) to capture images, frame-by-frame, where response is a boolean value that returns True if the frame is read in correctly. We can capture images in a loop, convert them to grayscale using the .cvtColor( ) method and display the image feed using .imshow( ) and .pause( ) (which pauses for an interval before updating the active figure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, frame = cap.read()\n",
    "ax = plt.gca()\n",
    "while response:\n",
    "    ax.clear()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    plt.imshow(frame, cmap = 'gray')\n",
    "    plt.pause(0.05)\n",
    "    response, frame = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define two functions:\n",
    "\n",
    "The first function, thresh_close_open, takes an image and a scalar, and thresholds an image (where the thresholding can be scaled by the scalar argument), clears the border, and then closes and opens the image before returning it. \n",
    "\n",
    "The second function, max_contour_diam, takes a binary image, retrieves its contours using the cv2 method .findContours( ), draws the filled contours using the cv2 method .drawContours( ), and then retrieves the largest diameter contour in the image. The average diameter of this largest contour is then determined by looking at the average distance between the contour and the image centroid, which is determined using the image moments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def thresh_close_open(image, thresh_scale):\n",
    "        \n",
    "    thresh = threshold_otsu(image)\n",
    "    binary = image > thresh * thresh_scale\n",
    "    \n",
    "    image_border = clear_border(binary)\n",
    "\n",
    "    close_ = closing(image_border)\n",
    "    open_ = opening(close_)\n",
    "    \n",
    "    return open_\n",
    "\n",
    "def max_contour_diam(image):\n",
    "    \n",
    "    _, contours, heirarchy = cv2.findContours(image.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    image = cv2.drawContours(image.astype(np.uint8), contours, -1, (127,127,127), 5)\n",
    "    \n",
    "    sort_cont = sorted(contours, key = cv2.contourArea)\n",
    "    largest = sort_cont[-1].tolist()\n",
    "    largest = sum(largest, [])\n",
    "    \n",
    "    M = moments(image)\n",
    "    x, y = M[1, 0] / M[0, 0], M[0, 1] / M[0, 0]\n",
    "    \n",
    "    norms = [np.sqrt((lar[0] - x)**2 + (lar[1] - y)**2) for lar in largest]\n",
    "    norm = np.mean(norms)\n",
    "    diameter = 2 * norm\n",
    "    \n",
    "    return diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct and deploy our first beam analysis tools: the average beam brightness and diameter retrieval tool. As above, we use the .read( ) function and a loop to capture images frame-by-frame, were we apply our image analysis to each frame. \n",
    "\n",
    "Here, we convert the color image to grayscale and compute the average brightness of the frame using np.mean( ). We then record this number by appending it to a list so the data can be plotted in real-time. Using an if statement, we ensure that the list does not exceed a length of 90, which allows us create a moving window to view the trend in the data over the past 90 frames. \n",
    "\n",
    "Next, we use our function thresh_close_open to return the frame after thresholding and opening and closing. We then feed this frame into our function max_contour_diam to back out the maximum contour diameter in the frame, which we then record by appending it to a list. This data is also visualized in real-time using an if statement to create another moving window to view the data trend over the past 90 frames, just as before. This data is then visualized using matplotlib and the .pause( ) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response, frame = cap.read()\n",
    "\n",
    "num = 90\n",
    "spacer = 10\n",
    "data = []\n",
    "diam = []\n",
    "i = 0\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (6, 4.5))\n",
    "\n",
    "while response:\n",
    "    \n",
    "    ax1.cla()\n",
    "    ax2.cla()\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ave = np.mean(frame)\n",
    "    if len(data) > num:\n",
    "        data.pop(0)\n",
    "        i = 90\n",
    "    data.append(ave)\n",
    "    \n",
    "    open_ = thresh_close_open(frame, 1.0)\n",
    "    \n",
    "    #_, contours, heirarchy = cv2.findContours(open_.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #open_ = cv2.drawContours(open_.astype(np.uint8), contours, -1, (127,127,127), 5)\n",
    "    \n",
    "    #diameter = max_contour_diam(contours, frame)\n",
    "    diameter = max_contour_diam(open_)\n",
    "    if len(diam) > num:\n",
    "        diam.pop(0)\n",
    "        i = 90\n",
    "    diam.append(diameter)\n",
    "    \n",
    "    ax1.set_xlim(0, num + spacer)\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_title('Brightness: {:06.3f}'.format(ave))\n",
    "    #ax1.set_title('Diameter: {:06.3f}'.format(diameter))\n",
    "    ax1.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "    ax1.plot(data)  #, label = 'Average Power: {:06.3f}'.format(ave))\n",
    "    ax1.scatter(i, ave, alpha = 0.9, s = 100)\n",
    "    #ax1.legend()\n",
    "\n",
    "    \n",
    "    ax2.set_xlim(0, num + spacer)\n",
    "    ax2.set_xticklabels([])\n",
    "    ax2.set_title('Diameter: {:06.3f}'.format(diameter))\n",
    "    ax2.tick_params(axis = 'x', bottom = False, labelbottom = False)\n",
    "    ax2.plot(diam)  #, label = 'Diameter: {:06.3f}'.format(diameter))\n",
    "    ax2.scatter(i, diameter, alpha = 0.9, s = 100)\n",
    "    #ax2.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.pause(0.05)\n",
    "    \n",
    "    response, frame = cap.read()\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can construct and deploy our beam centroiding tool. As before, we read in images frame-by-frame using the .read( ) function, which we convert to grayscale. Once we have a grayscale image, we apply our function thresh_close_open to the frame, before passing the modified frame to skimage's label( ) function, which labels all simply connected regions in the frame. To centroid the beam, we then loop over the regions retrieved by label( ) and check if a connected region is large enought to be a beam. If the beam is detected, the beam centroid, area and eccentricity is computed and then displayed on the original frame, where the centroid is marked on the frame by a red '+' symbol, and the area and eccentricity are displayed as the title. For comparison, we display both the original frame with the computed properties displayed, as well as the thresholded and closed and opened frame, by using np.hstack( ) to horizontally stack the two frame arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response, frame = cap.read()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (6, 4.5))\n",
    "\n",
    "while response:\n",
    "    \n",
    "    ax.cla()\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #thresh = threshold_otsu(frame)\n",
    "    #binary = frame > thresh * 1.7\n",
    "\n",
    "    #frame_border = clear_border(binary)\n",
    "    \n",
    "    #close_ = closing(frame_border)\n",
    "    #open_ = opening(close_)\n",
    "    \n",
    "    open_ = thresh_close_open(frame, 1.7)\n",
    "    \n",
    "    frame_regions = label(open_)\n",
    "    \n",
    "    #loop over the properties of labeled regions\n",
    "    for region in regionprops(frame_regions):\n",
    "    \n",
    "        #check if the region is big enough to be a beam\n",
    "        if region.area >= 500:\n",
    "                    \n",
    "            cent = region.centroid    \n",
    "            #cent = region.weighted_centroid\n",
    "            area = region.area\n",
    "            ecc = round(region.eccentricity, 3)\n",
    "            ax.text(cent[1], cent[0], '+', fontsize = 14,\n",
    "                horizontalalignment='center', verticalalignment='center', color = 'red',\n",
    "                fontdict = {'family': 'sans-serif', 'weight': 'bold'})\n",
    "            ax.set_title('Centroid: ({:02.1f},{:02.1f}), '.format(*cent) + 'Eccentricity: {:02.1f}, '.format(ecc) + \n",
    "                         'Area: {:02.1f}'.format(area), color = 'black',\n",
    "                fontdict = {'family': 'sans-serif', 'weight': 'bold', 'fontsize': 14})\n",
    "    \n",
    "    open_ = open_.astype(np.uint8)\n",
    "    open_[open_ == True] = 255\n",
    "    open_[open_ == False] = 0\n",
    "    stack_images = np.hstack([frame, open_])\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(stack_images, cmap = 'gray')\n",
    "    plt.pause(0.1)\n",
    "    response, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response, frame = cap.read()\n",
    "ax = plt.gca()\n",
    "while response:\n",
    "    ax.clear()\n",
    "    cap.set(cv2.CAP_PROP_GAIN, 0.0)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    thresh = threshold_otsu(frame)\n",
    "    binary = frame > thresh\n",
    "\n",
    "    close_ = closing(binary)\n",
    "    open_ = opening(close_)\n",
    "    \n",
    "    _, contours, heirarchy = cv2.findContours(open_.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    open_ = cv2.drawContours(open_.astype(np.uint8), contours, -1, (127,127,127), 5)\n",
    "\n",
    "    plt.imshow(open_, cmap = 'gray')\n",
    "    plt.pause(0.05)\n",
    "    response, frame = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
